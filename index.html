<!DOCTYPE HTML>
<!--
	Read Only by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Md Yousuf Harun</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<link rel="stylesheet" href="assets/academicons-1.9.1/css/academicons.min.css"/>

		<!-- Global site tag (gtag.js) - Google Analytics -->
		<!--<script async src="https://www.googletagmanager.com/gtag/js?id=UA-139312646-1"></script>
		<script>
		window.dataLayer = window.dataLayer || [];
		function gtag(){dataLayer.push(arguments);}
		gtag('js', new Date());

		gtag('config', 'UA-139312646-1');
		</script>-->

		
		
		<!-- Primary Meta Tags -->
		<meta name="title" content="Md Yousuf Harun">
		<meta name="description" content="My research focuses on continual/ lifelong machine learning.">

		<!-- Open Graph / Facebook -->
		<meta property="og:type" content="website">
		<meta property="og:url" content="https://yousuf907.github.io/">
		<meta property="og:title" content="Md Yousuf Harun">
		<meta property="og:description" content="My research focuses on continual/ lifelong machine learning.">
		<meta property="og:image" content="images/yousuf.jpeg">

		<!-- Twitter -->
		<meta property="twitter:card" content="summary_large_image">
		<meta property="twitter:url" content="https://yousuf907.github.io/">
		<meta property="twitter:title" content="Md Yousuf Harun">
		<meta property="twitter:description" content="My research focuses on continual/ lifelong machine learning.">
		<meta property="twitter:image" content="images/yousuf.jpeg">
	</head>

	<body class="is-preload">

		<!-- Header -->
		<section id="header">
			<header>
				<span class="image avatar"><img src="images/yousuf.jpeg" alt="" /></span>
				<h1 id="logo"><a href="#">Md Yousuf Harun</a></h1>
				<p> Ph.D. Student
				<br> Rochester Institute of Technology
				</p>
			</header>
			<nav id="nav">
				<ul>
					<li><a href="#about" class="active">About</a></li>
					<li><a href="#recent">Recent</a></li>
					<li><a href="#research">Research</a></li>
					<li><a href="#publications">Publications</a></li>
					<!--<li><a href="#blog">Blog</a></li>-->
				</ul>
			</nav>
			<footer>
				<ul class="icons">
					<li><a href="https://twitter.com/yousufovee007" class="icon fa-twitter"><span
								class="label">Twitter</span></a></li>
					<li><a href="https://github.com/yousuf907" class="icon fa-github"><span
								class="label">Github</span></a></li>
					<li><a href="https://www.linkedin.com/in/md-yousuf-harun-71748572" class="icon fa-linkedin"><span
								class="label">Linkedin</span></a></li>
					<li><a href="mailto:mh1023@rit.edu" class="icon solid fa-envelope"><span 
								class="label">Email</span></a></li>
					<li><a href="https://scholar.google.com/citations?hl=en&user=y8H0KTcAAAAJ" class="ai ai-google-scholar-square "></a></li>
				</ul>
			</footer>
		</section>

		<!-- Wrapper -->
		<div id="wrapper">

			<!-- Main -->
			<div id="main">

				<!-- About  -->
				<section id="about">
					<div class="image main" data-position="center">
						<img src="images/intro.jpeg" alt="" />
					</div>
					<div class="container">
						<h2>ABOUT ME</h2>
						<p align="justify"> Hello! I am a 5th year PhD student in the <a href="http://www.cis.rit.edu/">Chester F. Carlson Center for Imaging Science</a>
							at the <a href="https://www.rit.edu/">Rochester Institute of Technology (RIT)</a> in Rochester, NY.
							I currently work in the <a href="https://chriskanan.com/klab/">kLab</a> under the
							supervision of <a href="https://chriskanan.com/"><FONT COLOR="#0072b2">Dr. Christopher Kanan</FONT></a>. 
							My current research focuses on deep learning with an emphasis on continual/ lifelong machine learning.
							<b>My works have been published in NeurIPS, ICML, TMLR, CVPRW, and CoLLAs that advance the state-of-the-art in 
							deep learning and continual learning.</b>
						</p>
						<p align="justify">
							I received an MS in Electrical Engineering from <a href="https://manoa.hawaii.edu/">University of Hawaii</a> 
							and a BS in Electrical Engineering from <a href="https://www.kuet.ac.bd/">Khulna University of Engineering and Technology</a>.
							During MS, I worked on deep learning applied to medical imaging.
							My prior works have been published in IEEE NanoMed, ASRM conferences, and Reproductive BioMedicine Journal.
						</p>
						
						<p align="justify">
							ðŸ”® You can find my <span style="color:#25d399;">CV <a href="files/CV_Yousuf.pdf">here.</a></span>
						</p>
						<p align="justify">
							<!--Here is my <span style="color:#25d399;">Google Scholar <a href="https://scholar.google.com/citations?hl=en&user=y8H0KTcAAAAJ">.</a></span>-->
							ðŸ”® Here is my <a href="https://scholar.google.com/citations?hl=en&user=y8H0KTcAAAAJ" onclick="getOutboundLink(https://scholar.google.com/citations?hl=en&user=y8H0KTcAAAAJ); return false;" target="_blank"><button class="button">Google Scholar</button></a>
						</p>
					</div>
				</section>

				<!-- Recent -->
				<section id="recent">
					<div class="container">
						<h2>LATEST NEWS</h2>
						<p>	
							<b>May 2025:</b> Our paper <a href="https://arxiv.org/abs/2502.10691"><span style="color:#25d399;">"Controlling Neural Collapse Enhances Out-of-Distribution Detection and Transfer Learning"</span></a>
							has been accepted at ICML 2025! (26.9% accept rate) &#128293 <br>
							<!--<b>May 2024:</b> Our TMLR paper <a href="https://arxiv.org/abs/2303.10725"><span style="color:#25d399;">"SIESTA: Efficient Online Continual Learning with Sleep"</span></a>
							got accepted to the journal track of CoLLAs 2024! &#x1F525 <br>-->
							<b>Sep 2024:</b> Our paper <a href="https://arxiv.org/abs/2405.15018"><span style="color:#25d399;">"What Variables Affect Out-Of-Distribution Generalization in Pretrained Models?"</span></a>
							got accepted at NeurIPS 2024! (25.8% accept rate) &#128293 <br>
							<b>Sep 2024:</b> Our paper <a href="https://arxiv.org/abs/2306.01904"><span style="color:#25d399;">"Overcoming the Stability Gap in Continual Learning"</span></a>
							was accepted for publication in Transactions on Machine Learning Research (TMLR)! &#x1F389 <br>
							<b>April 2024:</b> Our paper <a href="https://arxiv.org/abs/2308.13646"><span style="color:#25d399;">"GRASP: A Rehearsal Policy for Efficient Online Continual Learning"</span></a>
							has been accepted to CoLLAs 2024, a premier conference in continual learning research! &#x1F389 <br>
							<b>Nov 2023:</b> Our paper <a href="https://arxiv.org/abs/2303.10725"><span style="color:#25d399;">"SIESTA: Efficient Online Continual Learning with Sleep"</span></a>
							was accepted for publication in Transactions on Machine Learning Research (TMLR)! &#x1F389 <br>
							<b>Nov 2023:</b> Won the "Best Student Abstract Award" at
							<a href="https://ewh.ieee.org/r1/rochester/sp/WNYISPW2023.html"><span style="color:#25d399;">IEEE 
							Western New York Image & Signal Processing Workshop 2023</span></a>. &#x1F389 <br>
							<!--<b>Oct 2023:</b> Gave an invited talk on <a href="https://www.youtube.com/watch?v=XGVcu7wNNzc&t=2s"><span style="color:#25d399;">"Towards Efficient Continual Learning in Deep Neural Networks"</span></a> at 
							RIT Center for Human-aware Artificial Intelligence (CHAI) Seminar Series.<br>-->
							<b>April 2023:</b> Our paper <a href="https://arxiv.org/abs/2303.18171"><span style="color:#25d399;">"How Efficient Are Today's Continual Learning Algorithms?"</span></a>
							got accepted in the CLVision Workshop at CVPR 2023! &#x1F389 <br>
							<!--<b>Jan 2022:</b> Got accepted in the <a href="https://www.rit.edu/nrtai/"><span style="color:#25d399;">AWARE-AI NRT</span></a> program from RIT as a Trainee! &#x1F60A <br>-->
							<!--<b>May 2021:</b> Joined the <a href="http://klab.cis.rit.edu/"><span style="color:#25d399;">Machine and Neuromorphic Perception Laboratory</span></a> as a PhD student. &#x1F60A <br>-->
							<!--<b>Aug 2020:</b> Got admitted to the <a href="https://www.rit.edu/"><span style="color:#25d399;">Rochester Institute of Technology</span></a> Imaging Science Ph.D. program! &#x1F60A <br>-->
							<!--<b>May 2020:</b> Successfully obtained my MS in Electrical Engineering from <a
								href="https://manoa.hawaii.edu"><span style="color:#25d399;">University of Hawaii</span></a>. &#x1F393 <br>-->
							<!--<b>Aug 2018:</b> Got admitted to the <a href="https://manoa.hawaii.edu"><span style="color:#25d399;">University of Hawaii</span></a> Electrical Engineering MS program! &#x1F60A <br>-->
							<!--<b>June 2017:</b> Joined <a href="https://www.dutchbanglabank.com"><span style="color:#25d399;">Dutch-Bangla Bank</span></a> as an Electrical Engineer. &#x1F60A <br>-->
							<!--<b>May 2016:</b> Successfully obtained my BS in Electrical & Electronic Engineering from <a
								href="https://www.kuet.ac.bd/"><span style="color:#25d399;">Khulna University of Engineering & Technology</span></a> in Khulna, Bangladesh. &#x1F393 <br>-->
						</p>
					</div>
				</section>

				<!-- Research -->
				<section id="research">
					<div class="container">
						<h2>RESEARCH</h2>
						<div class="features">

							<article>
								<div class="container">
									<h4>ICML 2025: Controlling Neural Collapse Enhances Out-of-Distribution Detection and Transfer Learning</h4>
									<p><strong>Md Yousuf Harun</strong>, Jhair Gallardo, Christopher Kanan</p>
									<h3>
										<a href="https://arxiv.org/abs/2502.10691" onclick="getOutboundLink('https://arxiv.org/abs/2502.10691'); return false;" target="_blank"><button class="button">arXiv</button></a>
										<a href="https://github.com/yousuf907/NC-OOD" onclick="getOutboundLink('https://github.com/yousuf907/NC-OOD'); return false;" target="_blank"><button class="button">Code</button></a>
										<a href="https://yousuf907.github.io/ncoodg" onclick="getOutboundLink('https://yousuf907.github.io/ncoodg'); return false;" target="_blank"><button class="button">Project Website</button></a>
									</h3>
								</div>

								<a class="image"><img src="images/nc_ood_detect_transfer_corr.png" alt="" /></a>
								<div class="inner">

									<p align="justify"> Out-of-distribution (OOD) detection and OOD generalization are widely studied in deep learning, 
										yet their relationship remains poorly understood. We empirically show that the degree of Neural 
										Collapse (NC) in a network layer is inversely related with these objectives: stronger NC improves OOD detection 
										but hurts generalization, while weaker NC does the opposite. This trade-off suggests that a single feature 
										space cannot simultaneously achieve both tasks. To address this, we develop a theoretical framework linking NC 
										to these objectives and propose a method to control NC across layers using entropy regularization for OOD generalization 
										and a fixed Simplex ETF projector for OOD detection.
									</p>
								</div>
							</article>


							<article>
								<div class="container">
									<h4>A Good Start Matters: Enhancing Continual Learning with Data-Driven Weight Initialization</h4>
									<p><strong>Md Yousuf Harun</strong>, Christopher Kanan</p>
									<h3>
										<a href="https://arxiv.org/abs/2503.06385" onclick="getOutboundLink('https://arxiv.org/abs/2503.06385'); return false;" target="_blank"><button class="button">arXiv</button></a>
									</h3>
								</div>

								<a class="image"><img src="images/speed_new_err.png" alt="" /></a>
								<div class="inner">

									<p align="justify"> Continual learning systems must efficiently learn new concepts while preserving prior 
										knowledge. However, randomly initializing classifier weights for new categories causes instability and 
										high initial loss, requiring prolonged training. Inspired by neural collapse, we propose a data-driven 
										weight initialization strategy using a least-square analytical solution, aligning weights with learned 
										features. This reduces loss spikes and accelerates adaptation.
									</p>
								</div>
							</article>


							<article>
								<div class="container">
									<h4>Improving Multimodal Large Language Models Using Continual Learning</h4>
									<p>Shikhar Srivastava, <strong>Md Yousuf Harun</strong>, Robik Shrestha, Christopher Kanan</p>
									<h3>
										<a href="https://arxiv.org/abs/2410.19925" onclick="getOutboundLink('https://arxiv.org/abs/2410.19925'); return false;" target="_blank"><button class="button">arXiv</button></a>
									</h3>
								</div>

								<a class="image"><img src="images/mllm.png" alt="" /></a>
								<div class="inner">

									<p align="justify"> Generative LLMs gain multimodal capabilities by integrating pre-trained vision 
										models, but this often leads to linguistic forgetting. We analyze this issue in LLaVA MLLM through a continual 
										learning lens, evaluating five methods to mitigate forgetting. Our approach reduces linguistic forgetting by up 
										to 15% while preserving multimodal accuracy. We also demonstrate its robustness in sequential vision-language 
										tasks, maintaining linguistic skills while acquiring new multimodal abilities.
									</p>
								</div>
							</article>


							<article>

								<div class="container">
									<h4>NeurIPS 2024: What Variables Affect Out-of-Distribution Generalization in Pretrained Models?</h4>
									<p><strong>Md Yousuf Harun*</strong>, Kyungbok Lee*, Jhair Gallardo, Giri Krishnan, Christopher Kanan <br>[* denotes equal contribution]</p>
									<h3>
										<a href="https://arxiv.org/abs/2405.15018" onclick="getOutboundLink('https://arxiv.org/abs/2405.15018'); return false;" target="_blank"><button class="button">arXiv</button></a>
										<a href="https://proceedings.neurips.cc/paper_files/paper/2024/hash/6701e9c94bc7c7d6b5fc47c0fc13ab5b-Abstract-Conference.html" onclick="getOutboundLink('https://proceedings.neurips.cc/paper_files/paper/2024/hash/6701e9c94bc7c7d6b5fc47c0fc13ab5b-Abstract-Conference.html'); return false;" target="_blank"><button class="button">Paper</button></a>
										<a href="https://github.com/yousuf907/Tunnel" onclick="getOutboundLink('https://github.com/yousuf907/Tunnel'); return false;" target="_blank"><button class="button">Code</button></a>
										<a href="files/NeurIPS_Poster_OOD_Gen.pdf" onclick="getOutboundLink('files/NeurIPS_Poster_OOD_Gen'); return false;" target="_blank"><button class="button">Poster</button></a>
										<a href="https://yousuf907.github.io/oodg" onclick="getOutboundLink('https://yousuf907.github.io/oodg'); return false;" target="_blank"><button class="button">Project Website</button></a>
									</h3>
								</div>

								<a class="image"><img src="images/the_tunnel_effect_updated.png" alt="" /></a>
								<div class="inner">
									<!--<h4><FONT COLOR="#A65628">NeurIPS 2024: What Variables Affect Out-Of-Distribution Generalization in Pretrained Models?</FONT></h4>
									<p><strong>Md Yousuf Harun</strong>, Kyungbok Lee, Jhair Gallardo, Giri Krishnan, Christopher Kanan</p>-->

									<p align="justify"> Embeddings produced by pre-trained deep neural networks (DNNs) are widely used; 
										however, their efficacy for downstream tasks can vary widely. We study the factors influencing 
										out-of-distribution (OOD) generalization of pre-trained DNN embeddings through the lens of the 
										<b>tunnel effect</b> hypothesis, which suggests deeper DNN layers compress representations and hinder 
										OOD performance. Contrary to earlier work, we find the tunnel effect is not universal. Our results 
										emphasize the danger of generalizing findings from toy datasets to broader contexts.
									</p>
									<!--<h4>&#10024<FONT COLOR="#0072b2">NeurIPS 2024</FONT>&#10024</h4>
									<h3>
										<a href="https://arxiv.org/abs/2405.15018" onclick="getOutboundLink('https://arxiv.org/abs/2405.15018'); return false;" target="_blank"><button class="button">arXiv</button></a>
										<a href="https://github.com/yousuf907/Tunnel" onclick="getOutboundLink('https://github.com/yousuf907/Tunnel'); return false;" target="_blank"><button class="button">Code</button></a>
										<a href="https://yousuf907.github.io/oodg" onclick="getOutboundLink('https://yousuf907.github.io/oodg'); return false;" target="_blank"><button class="button">Project Website</button></a>
									</h3>-->
								</div>
							</article>

							<article>

								<div class="container">
									<h4>CoLLAs 2024: GRASP: A Rehearsal Policy for Efficient Online Continual Learning</h4>
									<p><strong>Md Yousuf Harun</strong>, Jhair Gallardo, Junyu Chen, Christopher Kanan</p>
									<h3>
										<a href="https://arxiv.org/abs/2308.13646" onclick="getOutboundLink('https://arxiv.org/abs/2308.13646'); return false;" target="_blank"><button class="button">arXiv</button></a>
										<a href="https://proceedings.mlr.press/v274/harun25a.html" onclick="getOutboundLink('https://proceedings.mlr.press/v274/harun25a.html'); return false;" target="_blank"><button class="button">Paper</button></a>
										<a href="https://github.com/yousuf907/GRASP" onclick="getOutboundLink('https://github.com/yousuf907/GRASP'); return false;" target="_blank"><button class="button">Code</button></a>
										<a href="files/Updated_Poster_GRASP_CoLLAs_2024.pdf" onclick="getOutboundLink('files/Updated_Poster_GRASP_CoLLAs_2024'); return false;" target="_blank"><button class="button">Poster</button></a>
										<a href="https://youtu.be/LWprK5OVW5w" onclick="getOutboundLink('https://youtu.be/LWprK5OVW5w'); return false;" target="_blank"><button class="button">Video</button></a>
										<a href="https://yousuf907.github.io/graspsite" onclick="getOutboundLink('https://yousuf907.github.io/graspsite'); return false;" target="_blank"><button class="button">Project Website</button></a>
									</h3>
								</div>

								<a class="image"><img src="images/compute_replay_updated.png" alt="" /></a>
								<div class="inner">
									<!--<h4><FONT COLOR="#A65628">GRASP: A Rehearsal Policy for Efficient Online Continual Learning</FONT></h4>
									<p><strong>Md Yousuf Harun</strong>, Jhair Gallardo, Junyu Chen, Christopher Kanan</p>-->

									<p align="justify"> In this work, we propose a new sample selection or rehearsal policy called GRASP (GRAdually 
										Select less Prototypical) for efficient continual learning (CL).
										GRASP is a dynamic rehearsal policy that progressively selects harder samples over time to efficiently
										update deep neural networks on large-scale data streams in CL settings. GRASP is the first method to outperform
										uniform balanced sampling in both large-scale vision and NLP datasets. GRASP has potential to supplant expensive periodic retraining 
										and make on-device CL more efficient.
									</p>
									<!--<h4>&#10024<FONT COLOR="#0072b2">CoLLAs 2024</FONT>&#10024</h4>
									<h3>
										<a href="https://arxiv.org/abs/2308.13646" onclick="getOutboundLink('https://arxiv.org/abs/2308.13646'); return false;" target="_blank"><button class="button">arXiv</button></a>
										<a href="https://github.com/yousuf907/GRASP" onclick="getOutboundLink('https://github.com/yousuf907/GRASP'); return false;" target="_blank"><button class="button">Code</button></a>
										<a href="files/Updated_Poster_GRASP_CoLLAs_2024.pdf" onclick="getOutboundLink('files/Updated_Poster_GRASP_CoLLAs_2024'); return false;" target="_blank"><button class="button">Poster</button></a>
										<a href="https://yousuf907.github.io/graspsite" onclick="getOutboundLink('https://yousuf907.github.io/graspsite'); return false;" target="_blank"><button class="button">Project Website</button></a>
									</h3>-->
								</div>
							</article>

							<article>

								<div class="container">
									<h4>TMLR 2024: Overcoming the Stability Gap in Continual Learning</h4>
									<p><strong>Md Yousuf Harun</strong>, Christopher Kanan</p>
									<h3>
										<a href="https://arxiv.org/abs/2306.01904" onclick="getOutboundLink('https://arxiv.org/abs/2306.01904'); return false;" target="_blank"><button class="button">arXiv</button></a>
										<a href="https://openreview.net/pdf?id=o2wEfwUOma" onclick="getOutboundLink('https://openreview.net/pdf?id=o2wEfwUOma'); return false;" target="_blank"><button class="button">Paper</button></a>
										<a href="https://github.com/yousuf907/SGM" onclick="getOutboundLink('https://github.com/yousuf907/SGM'); return false;" target="_blank"><button class="button">Code</button></a>
										<a href="https://yousuf907.github.io/sgmsite" onclick="getOutboundLink('https://yousuf907.github.io/sgmsite'); return false;" target="_blank"><button class="button">Project Website</button></a>
									</h3>
								</div>

								<a class="image"><img src="images/sgm_intro.png" alt="" /></a>
								<div class="inner">
									<!--<h4><FONT COLOR="#A65628">Overcoming the Stability Gap in Continual Learning</FONT></h4>
									<p><strong>Md Yousuf Harun</strong>, Christopher Kanan</p>-->

									<p align="justify"> 

										Pre-trained deep neural networks (DNNs) are being widely deployed by industry for making business decisions 
										and to serve users; however, a major problem is <b>model decay</b>. To mitigate model decay, DNNs are retrained from scratch 
										which is computationally expensive. In this work, we study how continual learning could overcome model decay and reduce computational costs.
										We identify the <b>stability gap</b> as a major obstacle in our setting. We study how to mitigate the stability gap and test a variety of hypotheses. 
										This leads us to discover a method that vastly reduces the stability gap and greatly increases computational efficiency. 								
									</p>
									<!--<h4>Under Review 2023</h4>-->
									<!--<h4>&#10024<FONT COLOR="#0072b2">TMLR 2024</FONT>&#10024</h4>
									<h3>
										<a href="https://arxiv.org/abs/2306.01904" onclick="getOutboundLink('https://arxiv.org/abs/2306.01904'); return false;" target="_blank"><button class="button">arXiv</button></a>
										<a href="https://openreview.net/pdf?id=o2wEfwUOma" onclick="getOutboundLink('https://openreview.net/pdf?id=o2wEfwUOma'); return false;" target="_blank"><button class="button">Paper</button></a>
										<a href="https://github.com/yousuf907/SGM" onclick="getOutboundLink('https://github.com/yousuf907/SGM'); return false;" target="_blank"><button class="button">Code</button></a>
										<a href="https://yousuf907.github.io/sgmsite" onclick="getOutboundLink('https://yousuf907.github.io/sgmsite'); return false;" target="_blank"><button class="button">Project Website</button></a>
									</h3>-->
								</div>
							</article>

							<article>

								<div class="container">
									<h4>TMLR 2023: SIESTA: Efficient Online Continual Learning with Sleep</h4>
									<p><b>Md Yousuf Harun*</b>, Jhair Gallardo*, Tyler L. Hayes, Ronald Kemker, Christopher Kanan <br>[* denotes equal contribution, also presented at the Journal Track of CoLLAs 2024]</p>
									<h3>
										<a href="https://arxiv.org/abs/2303.10725" onclick="getOutboundLink('https://arxiv.org/abs/2303.10725'); return false;" target="_blank"><button class="button">arXiv</button></a>
										<a href="https://openreview.net/pdf?id=MqDVlBWRRV" onclick="getOutboundLink('https://openreview.net/pdf?id=MqDVlBWRRV'); return false;" target="_blank"><button class="button">Paper</button></a>
										<a href="https://github.com/yousuf907/SIESTA" onclick="getOutboundLink('https://github.com/yousuf907/SIESTA'); return false;" target="_blank"><button class="button">Code</button></a>
										<a href="files/Updated_Poster_SIESTA_CoLLAs_2024.pdf" onclick="getOutboundLink('files/Updated_Poster_SIESTA_CoLLAs_2024'); return false;" target="_blank"><button class="button">Poster</button></a>
										<a href="https://youtu.be/fbaqINofHnw" onclick="getOutboundLink('https://youtu.be/fbaqINofHnw'); return false;" target="_blank"><button class="button">Video</button></a>
										<a href="https://yousuf907.github.io/siestasite" onclick="getOutboundLink('https://yousuf907.github.io/siestasite'); return false;" target="_blank"><button class="button">Project Website</button></a>
									</h3>
								</div>


								<a class="image"><img src="images/siesta_summary.png" alt="" /></a>
								<div class="inner">
									<!--<h4><FONT COLOR="#A65628">SIESTA: Efficient Online Continual Learning with Sleep</FONT></h4>
									<p><b>Md Yousuf Harun</b>, Jhair Gallardo, Tyler L. Hayes, Ronald Kemker, Christopher Kanan</p>-->
									
									<p align="justify"> For continual learning (CL) to make a real-world impact, CL systems need to provide 
										computational efficiency and rival traditional offline learning systems retrained from scratch. Towards 
										that goal, we propose a novel online CL algorithm named SIESTA. SIESTA uses a wake/sleep framework for 
										training, which is well aligned to the needs of on-device learning. SIESTA is far more computationally efficient 
										than existing methods, enabling CL on ImageNet-1K in under 2 hours; moreover, it achieves <b>"zero forgetting"</b> 
										by matching the performance of the joint model, a milestone critical to driving adoption of CL in 
										real-world applications.								
									</p>
									<!--<h4>&#10024<FONT COLOR="#0072b2">TMLR 2023</FONT>&#10024</h4>
									<h3>
										<a href="https://arxiv.org/abs/2303.10725" onclick="getOutboundLink('https://arxiv.org/abs/2303.10725'); return false;" target="_blank"><button class="button">arXiv</button></a>
										<a href="https://openreview.net/pdf?id=MqDVlBWRRV" onclick="getOutboundLink('https://openreview.net/pdf?id=MqDVlBWRRV'); return false;" target="_blank"><button class="button">Paper</button></a>
										<a href="https://github.com/yousuf907/SIESTA" onclick="getOutboundLink('https://github.com/yousuf907/SIESTA'); return false;" target="_blank"><button class="button">Code</button></a>
										<a href="files/Updated_Poster_SIESTA_CoLLAs_2024.pdf" onclick="getOutboundLink('files/Updated_Poster_SIESTA_CoLLAs_2024'); return false;" target="_blank"><button class="button">Poster</button></a>
										<a href="https://yousuf907.github.io/siestasite" onclick="getOutboundLink('https://yousuf907.github.io/siestasite'); return false;" target="_blank"><button class="button">Project Website</button></a>
									</h3>-->
								</div>
							</article>

							<article>

								<div class="container">
									<h4>CVPRW 2023: How Efficient Are Today's Continual Learning Algorithms?</h4>
									<p><strong>Md Yousuf Harun</strong>, Jhair Gallardo, Tyler L. Hayes, Christopher Kanan</p>
									<h3>
										<a href="https://arxiv.org/abs/2303.18171" onclick="getOutboundLink('https://arxiv.org/abs/2303.18171'); return false;" target="_blank"><button class="button">arXiv</button></a>
										<a href="https://openaccess.thecvf.com/content/CVPR2023W/CLVision/papers/Harun_How_Efficient_Are_Todays_Continual_Learning_Algorithms_CVPRW_2023_paper.pdf" onclick="getOutboundLink('https://openaccess.thecvf.com/content/CVPR2023W/CLVision/papers/Harun_How_Efficient_Are_Todays_Continual_Learning_Algorithms_CVPRW_2023_paper.pdf'); return false;" target="_blank"><button class="button">Paper</button></a>
										<a href="files/Poster_CVPRW_2023.pdf" onclick="getOutboundLink('files/Poster_CVPRW_2023.pdf'); return false;" target="_blank"><button class="button">Poster</button></a>
									</h3>
								</div>



								<a class="image"><img src="images/plot_compute_icml.png" alt="" /></a>
								<div class="inner">
									<!--<h4><FONT COLOR="#A65628">How Efficient Are Today's Continual Learning Algorithms?</FONT></h4>
									<p><strong>Md Yousuf Harun</strong>, Jhair Gallardo, Tyler L. Hayes, Christopher Kanan</p>-->
									
									<p align="justify"> Continual learning (CL) has focused on catastrophic forgetting, but a major motivation 
										for CL is efficiently updating deep neural networks (DNNs) with new data, 
										rather than retraining from scratch when dataset grows over time.
										We study the computational efficiency of existing CL methods which reveals that many are 
										as expensive as training offline models from scratch. This defeats the efficiency aspect of CL.
									</p>
									<!--<h4>&#10024<FONT COLOR="#0072b2">CVPR-W 2023</FONT>&#10024</h4>
									<h3>
										<a href="https://arxiv.org/abs/2303.18171" onclick="getOutboundLink('https://arxiv.org/abs/2303.18171'); return false;" target="_blank"><button class="button">arXiv</button></a>
										<a href="https://openaccess.thecvf.com/content/CVPR2023W/CLVision/papers/Harun_How_Efficient_Are_Todays_Continual_Learning_Algorithms_CVPRW_2023_paper.pdf" onclick="getOutboundLink('https://openaccess.thecvf.com/content/CVPR2023W/CLVision/papers/Harun_How_Efficient_Are_Todays_Continual_Learning_Algorithms_CVPRW_2023_paper.pdf'); return false;" target="_blank"><button class="button">Paper</button></a>
										<a href="files/Poster_CVPRW_2023.pdf" onclick="getOutboundLink('files/Poster_CVPRW_2023.pdf'); return false;" target="_blank"><button class="button">Poster</button></a>
									</h3>-->
								</div>
							</article>

						</div>
					</div>
				</section>

				<!-- Research -->
				<section id="publications">
					<div class="container">
						<h2>PUBLICATIONS</h2>
						<h1><FONT COLOR="#0072b2">Pre-Prints</FONT></h1>
						<ul>

							<li><strong>M.Y. Harun</strong>, C. Kanan.
								<a href="https://arxiv.org/abs/2503.06385">
									A Good Start Matters: Enhancing Continual Learning with Data-Driven Weight Initialization.
								</a> ArXiv, 2025
							</li>

							<li>S. Srivastava, <strong>M.Y. Harun</strong>, R. Shrestha, C. Kanan.
								<a href="https://arxiv.org/abs/2410.19925">
									Improving Multimodal Large Language Models Using Continual Learning.
								</a> ArXiv, 2024
							</li>
						</ul>
						<h1><FONT COLOR="#0072b2">Peer-Reviewed Papers</FONT></h1>
						<ul>
							<li><strong>M.Y. Harun</strong>, J. Gallardo, C. Kanan.
								<a href="https://arxiv.org/abs/2502.10691">
									Controlling Neural Collapse Enhances Out-of-Distribution Detection and Transfer Learning.
								</a> In: International Conference on Machine Learning (ICML), 2025 [26.9% accept rate]
							</li>

							<li><strong>M.Y. Harun</strong>, K. Lee, J. Gallardo, G. Krishnan, C. Kanan.
								<a href="https://arxiv.org/abs/2405.15018">
									What Variables Affect Out-Of-Distribution Generalization in Pretrained Models?
								</a> In: Neural Information Processing Systems (NeurIPS), 2024 [25.8% accept rate]
							</li>

							<li><strong>M.Y. Harun</strong>, C. Kanan.
								<a href="https://arxiv.org/abs/2306.01904">
									Overcoming the Stability Gap in Continual Learning
								</a>. In: Transactions on Machine Learning Research (TMLR), 2024
							</li>

							<li><strong>M.Y. Harun</strong>, J. Gallardo, J. Chen, C. Kanan.
								<a href="https://arxiv.org/abs/2308.13646">
									GRASP: A Rehearsal Policy for Efficient Online Continual Learning
								</a>. In: Conference on Lifelong Learning Agents (CoLLAs), 2024
							</li>

							<li><strong>M.Y. Harun</strong>, J. Gallardo, T.L. Hayes, R. Kemker, C. Kanan.
								<a href="https://arxiv.org/abs/2303.10725">
									SIESTA: Efficient Online Continual Learning with Sleep
								</a>. In: Transactions on Machine Learning Research (TMLR), 2023
							</li>

							<li><strong>M.Y. Harun</strong>, J. Gallardo, T.L. Hayes, C. Kanan.
								<a href="https://arxiv.org/abs/2303.18171">
									How Efficient Are Today's Continual Learning Algorithms?
								</a>. In: CVPR Continual Learning in Computer Vision Workshop (CVPR-CLVision), 2023
							</li>

							<li>T.T. Huang, T. Kosasa, B. Walker, C. Arnett, C.T. Huang, C. Yin, <strong>M.Y. Harun</strong>, H.J. Ahn, A. Ohta.
								<a href="https://www.sciencedirect.com/science/article/abs/pii/S1472648321001012">
									Deep Learning Neural Network Analysis of Human Blastocyst Analysis from Time-lapse Image Files
								</a>. In: Reproductive BioMedicine Online, 2021
							</li>

							<li><strong>M.Y. Harun</strong>, M.A. Rahman, J. Mellinger, W. Chang, T. Huang, B. Walker, K. Hori, A. Ohta.
								<a href="https://ieeexplore.ieee.org/document/9130621">
									Image Segmentation of Zona-Ablated Human Blastocysts
								</a>. In: Proc. IEEE Intl. Conference on Nano/Molecular Medicine & Engineering (NANOMED), 2019
							</li>

							<li><strong>M.Y. Harun</strong>, T. Huang, B. Walker, A. Ohta.
								<a href="https://ieeexplore.ieee.org/document/9130618">
									Inner Cell Mass and Trophectoderm Segmentation in Human Blastocyst Images using Deep Neural Network
								</a>. In: Proc. IEEE Intl. Conference on Nano/Molecular Medicine & Engineering (NANOMED), 2019
							</li>
						</ul> 
						<h1><FONT COLOR="#0072b2">Poster</FONT></h1>
						<ul>
							<li>T. Huang, B. Walker, <strong>M.Y. Harun</strong>, M.A. Rahman, J. Mellinger, W. Chang, A. Ohta.
								<a href="https://www.fertstert.org/article/S0015-0282(19)31463-3/fulltext">
									Automated Computer Analysis of Human Blastocyst Expansion from Embryoscope Time-Lapse Image Files
								</a>. In: American Society for Reproductive Medicine (ASRM), 2019
							</li>
						</ul>
						<h1><FONT COLOR="#0072b2">Dissertation</FONT></h1>
						<ul>
							<li><strong>M.Y. Harun</strong>.
								<a href="https://scholarspace.manoa.hawaii.edu/handle/10125/68984">
									Medical Image Segmentation for Embryo Image Analysis
								</a>. MS Dissertation, University of Hawaii, 2018
							</li>
						</ul>
					</div>
				</section>

				<!-- Blog -->
				<!--
				<section id="blog">
						<div class="container">
							<h3>Blog</h3>
							<p>Go to my blog <a href="blog/index.html">here</a></p>
						</div>
				</section>
				-->

			</div>

			<!-- Footer -->
			<section id="footer">
				<div class="container">
					<ul class="copyright">
						<li>&copy; 2020. Md Yousuf Harun.</li>
						<li>Design: <a href="http://html5up.net">HTML5 UP</a></li>
					</ul>
				</div>
			</section>

		</div>

		<!-- Scripts -->
		<script src="assets/js/jquery.min.js"></script>
		<script src="assets/js/jquery.scrollex.min.js"></script>
		<script src="assets/js/jquery.scrolly.min.js"></script>
		<script src="assets/js/browser.min.js"></script>
		<script src="assets/js/breakpoints.min.js"></script>
		<script src="assets/js/util.js"></script>
		<script src="assets/js/main.js"></script>

	</body>

</html>
